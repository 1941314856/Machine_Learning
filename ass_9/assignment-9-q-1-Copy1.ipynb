{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as  np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropping output column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('data.csv')\n",
    "total_y_values = original_data['xAttack']\n",
    "original_data = original_data.drop('xAttack',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
      "0 -0.114536 -0.425928  -0.010012  -0.034506 -0.090954          -0.026321   \n",
      "1 -0.114536  0.362284  -0.010092  -0.039818 -0.090954          -0.026321   \n",
      "2 -0.114536 -0.425928  -0.010023   0.077314 -0.090954          -0.026321   \n",
      "3 -0.114536 -0.729086  -0.009539  -0.039818 -0.090954          -0.026321   \n",
      "4 -0.114536  0.301652  -0.010092  -0.039818 -0.090954          -0.026321   \n",
      "\n",
      "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
      "0        -0.021938 -0.021801           -0.027915         -0.044086  ...   \n",
      "1        -0.021938 -0.021801           -0.027915         -0.044086  ...   \n",
      "2        -0.021938 -0.021801           -0.027915         -0.044086  ...   \n",
      "3        -0.021938 -0.021801           -0.027915         -0.044086  ...   \n",
      "4        -0.021938 -0.021801           -0.027915         -0.044086  ...   \n",
      "\n",
      "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
      "0       -1.690179            1.262846                1.067550   \n",
      "1        0.732932           -1.032492               -1.159522   \n",
      "2       -1.447868            1.262846                1.067550   \n",
      "3       -0.488720           -0.761389               -0.647295   \n",
      "4        0.732932           -0.815609               -0.936814   \n",
      "\n",
      "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
      "0               -0.441075                    -0.253420   \n",
      "1               -0.069608                    -0.479712   \n",
      "2               -0.441075                    -0.382730   \n",
      "3               -0.228808                     0.263818   \n",
      "4               -0.175741                    -0.479712   \n",
      "\n",
      "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
      "0                     0.071029             -0.639487   \n",
      "1                    -0.289000             -0.639487   \n",
      "2                     0.251043             -0.639487   \n",
      "3                    -0.289000             -0.594495   \n",
      "4                    -0.289000              1.610076   \n",
      "\n",
      "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
      "0                 -0.535321             -0.386069                 -0.374975  \n",
      "1                 -0.625133              2.878183                  2.771083  \n",
      "2                 -0.625133             -0.386069                 -0.374975  \n",
      "3                 -0.625133             -0.386069                 -0.374975  \n",
      "4                  1.620172             -0.386069                 -0.374975  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "total_y_values = data['xAttack']\n",
    "data = data.drop('xAttack',axis = 1)\n",
    "\n",
    "data=data.astype('float128')\n",
    "data_mean = deepcopy(data.mean())\n",
    "data_std = deepcopy(data.std())\n",
    "data =(data-data_mean)*np.float128(1.0)/data_std\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114536</td>\n",
       "      <td>-0.425928</td>\n",
       "      <td>-0.010012</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>-0.090954</td>\n",
       "      <td>-0.026321</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027915</td>\n",
       "      <td>-0.044086</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690179</td>\n",
       "      <td>1.262846</td>\n",
       "      <td>1.06755</td>\n",
       "      <td>-0.441075</td>\n",
       "      <td>-0.25342</td>\n",
       "      <td>0.071029</td>\n",
       "      <td>-0.639487</td>\n",
       "      <td>-0.535321</td>\n",
       "      <td>-0.386069</td>\n",
       "      <td>-0.374975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114536 -0.425928  -0.010012  -0.034506 -0.090954          -0.026321   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0        -0.021938 -0.021801           -0.027915         -0.044086  ...   \n",
       "\n",
       "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0       -1.690179            1.262846                 1.06755   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0               -0.441075                     -0.25342   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                     0.071029             -0.639487   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                 -0.535321             -0.386069                 -0.374975  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1.0 / (1.0 + np.exp(-z)))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def sigmoid_der(z):\n",
    "    return np.multiply(sigmoid(z), (1.0 - sigmoid(z)))\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def relu_der(x):\n",
    "    x[x <= 0] = 0\n",
    "    x[x > 0] = 1\n",
    "    return x\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def tanh_der(x):\n",
    "    return 1.0 - (np.power(tanh(x), 2))\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    expA = np.exp(Z - Z.max(1).reshape(Z.shape[0], 1))\n",
    "    esum = expA / np.sum(expA, 1).reshape(Z.shape[0], 1)\n",
    "    return esum\n",
    "\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def linear_der(z):\n",
    "    return 1\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "def softmax_der(x):\n",
    "    y = deepcopy(x)\n",
    "    edeno = np.power(np.sum(np.exp(x)), 2)\n",
    "    enumo = np.sum(np.exp(x))\n",
    "    for ele in y:\n",
    "        for k in range(len(ele)):\n",
    "            tempy = y[0][k]\n",
    "            y[0][k] = (np.exp(tempy) * (enumo - np.exp(tempy)) / edeno)\n",
    "    return y\n",
    "\n",
    "\n",
    "# ### Layer class\n",
    "# >- layer class will hold all the information regarding each layer\n",
    "# >- each layer will have many attributes such as\n",
    "# >>- number of nodes in each layer\n",
    "# >>- activation function\n",
    "# >>- derivatives regarding gradient decent\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "class layer:\n",
    "    def __init__(self, layerno, num_of_nodes, activation_function, isinput,\n",
    "                 isoutput, ishidden):\n",
    "        self.layerno = layerno\n",
    "        self.num_of_nodes = num_of_nodes\n",
    "        self.activation_function = activation_function\n",
    "        self.is_input_layer = isinput\n",
    "        self.is_ouput_layer = isoutput\n",
    "        self.is_hidden_layer = ishidden\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.error_cost = np.float128(1.0)\n",
    "        self.derivative_op = np.float128(1.0)\n",
    "        self.derivative_act = np.float128(1.0)\n",
    "        self.derivative_wt = np.float128(1.0)\n",
    "        self.k_product = np.float128(1.0)\n",
    "\n",
    "\n",
    "# ### Function that generate random weights of shape of ( layer n-1 , layer n )\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "def getrandom_wts(numberofnodes_prev, numberofnodes_next):\n",
    "    return (0.01 * (np.random.randn(numberofnodes_prev, numberofnodes_next)))\n",
    "\n",
    "\n",
    "# ### Common activation fucntion that will be called\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "def activation(z, function_name):\n",
    "    if function_name == 'sigmoid':\n",
    "        return sigmoid(z)\n",
    "    if function_name == 'tanh':\n",
    "        return tanh(z)\n",
    "    if function_name == 'relu':\n",
    "        return relu(z)\n",
    "    if function_name == \"softmax\":\n",
    "        return softmax(z)\n",
    "    if function_name == \"linear\":\n",
    "        return linear(z)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "def activation_der(z, function_name):\n",
    "    if function_name == 'sigmoid':\n",
    "        return sigmoid_der(z)\n",
    "    if function_name == 'tanh':\n",
    "        return tanh_der(z)\n",
    "    if function_name == 'relu':\n",
    "        return relu_der(z)\n",
    "    if function_name == \"softmax\":\n",
    "        return softmax_der(z)\n",
    "    if function_name == \"linear\":\n",
    "        return linear_der(z)\n",
    "\n",
    "\n",
    "# ### Class neural net\n",
    "# >- It holds the structure of the neural net\n",
    "# >- It has following methods\n",
    "# >- 1. Initializer :\n",
    "# >>- it intializes the hyper parameters like learning rate, number of epochs and batch size.\n",
    "# >- 2. Add layer:\n",
    "# >>- It adds a layer to neural net, we can define activation function, number of nodes in each layer.\n",
    "# >- 3. Forward propogation\n",
    "# >- 4. Backward propogation\n",
    "# >- 5. Predict\n",
    "# >- 6. Fit\n",
    "# >>- Train the neural network using forward and back ward propogation\n",
    "\n",
    "# In[123]:\n",
    "\n",
    "\n",
    "class neural_net:\n",
    "    layerno = 0\n",
    "\n",
    "    def __init__(self, numboflayer, learning_rate, epochs, batch_size):\n",
    "        self.numboflayer = numboflayer\n",
    "        self.layers = []\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weight_matrix = None\n",
    "        self.batch_size = batch_size\n",
    "        self.error_each_epoch = []\n",
    "        self.acc_each_epoch = []\n",
    "        neural_net.layerno = 0\n",
    "        self.compressed_output = None\n",
    "        self.bottleneck_layer_no = (numboflayer - 1)//2\n",
    "\n",
    "    def predict(self, y, actual_y):\n",
    "        rcount = 0\n",
    "        wcount = 0\n",
    "        for ind, i in enumerate(y):\n",
    "            self.forward_propogation(np.array(i).reshape(1, len(i)))\n",
    "            list_of_op = list(np.ndarray.flatten(self.layers[-1].output))\n",
    "            index = list_of_op.index(max(list_of_op))\n",
    "            if (actual_y[ind][index] == 1):\n",
    "                rcount += 1\n",
    "            else:\n",
    "                wcount += 1\n",
    "        print(\"right count: \", rcount)\n",
    "        print(\"wrong count: \", wcount)\n",
    "        print(\"Accuracy\", rcount / (rcount + wcount))\n",
    "        self.acc_each_epoch.append(rcount / (rcount + wcount))\n",
    "        print()\n",
    "\n",
    "    def predict_2(self, y):\n",
    "        rcount = 0\n",
    "        wcount = 0\n",
    "        f = open(\"2018201004_prediction.csv\", \"w+\")\n",
    "        for ind, i in enumerate(y):\n",
    "            self.forward_propogation(np.array(i).reshape(1, len(i)))\n",
    "            list_of_op = list(np.ndarray.flatten(self.layers[-1].output))\n",
    "            index = list_of_op.index(max(list_of_op))\n",
    "            f.write(str(int(index)))\n",
    "            if ind != (len(y) - 1):\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    def test_data(self, test_inp, test_op):\n",
    "        self.test_inp = test_inp\n",
    "        self.test_op = test_op\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.no_of_batches = (len(x) // self.batch_size)\n",
    "        if self.no_of_batches * self.batch_size != len(x):\n",
    "            self.no_of_batches += 1\n",
    "        flag_of_learningrate = 0\n",
    "        for epoc in range(self.epochs):\n",
    "            print(\"epoch: \", epoc)\n",
    "            error_batch = 0.0\n",
    "            #             for batchno in range(self.no_of_batches):\n",
    "            #                 startindex = batchno*self.batch_size\n",
    "            #                 endindex = min((batchno+1)*self.batch_size , len(x))\n",
    "            #print(len(x))\n",
    "            for rowindex in range(0, len(x)):\n",
    "                self.forward_propogation(\n",
    "                    np.array(x[rowindex]).reshape(1, len(x[rowindex])))\n",
    "                self.backward_propogation(\n",
    "                    np.array(y[rowindex]).reshape(1, len(y[rowindex])))\n",
    "                error_batch += self.layers[-1].error\n",
    "\n",
    "            self.error_each_epoch.append(error_batch)\n",
    "            print(\"Error: \", error_batch/len(x))\n",
    "#             if(error_batch/len(x) < 15 and not flag_of_learningrate):\n",
    "#                 self.learning_rate = self.learning_rate/10\n",
    "#                 flag_of_learningrate = 1\n",
    "#            print(self.layers[-1].output)\n",
    "#            self.predict(self.test_inp, self.test_op)\n",
    "#             for layer in self.layers:\n",
    "#                 if layer.layerno != 0:\n",
    "#                     print(\"weights\",self.weights[layer.layerno-1])\n",
    "#                 print(\"layerno\",layer.layerno)\n",
    "#                 print(\"input\",layer.input)\n",
    "#                 print(\"output\",layer.output)\n",
    "#                 print(\"serivative1\",layer.derivative_op)\n",
    "#                 print(\"derivative2\",layer.derivative_act)\n",
    "#                 print(\"kproduct\",layer.k_product)\n",
    "#                 print(\"derivative3\",layer.derivative_wt)\n",
    "\n",
    "    def add_layer(self, num_of_nodes, activation_function):\n",
    "        if neural_net.layerno == 0:\n",
    "            temp_layer = layer(neural_net.layerno, num_of_nodes,\n",
    "                               activation_function, True, False, False)\n",
    "        elif neural_net.layerno == self.numboflayer - 1:\n",
    "            temp_layer = layer(neural_net.layerno, num_of_nodes,\n",
    "                               activation_function, False, True, False)\n",
    "        else:\n",
    "            temp_layer = layer(neural_net.layerno, num_of_nodes,\n",
    "                               activation_function, False, False, True)\n",
    "\n",
    "        neural_net.layerno += 1\n",
    "\n",
    "        self.layers.append(temp_layer)\n",
    "\n",
    "        if (temp_layer.is_input_layer == False):\n",
    "            #self.weights.append(random_wts[temp_layer.layerno-1])\n",
    "            #print(temp_layer.layerno)\n",
    "            self.weights.append(\n",
    "                getrandom_wts(self.layers[temp_layer.layerno - 1].num_of_nodes,\n",
    "                              temp_layer.num_of_nodes))\n",
    "            self.bias.append(np.random.randn(1, temp_layer.num_of_nodes))\n",
    "\n",
    "        #self.weights = np.array(self.weights)\n",
    "    def get_compressed_datamatrix(self,x):\n",
    "        output_rows = []\n",
    "        for rowindex in range(len(x)):\n",
    "            self.forward_propogation(\n",
    "                    np.array(x[rowindex]).reshape(1, len(x[rowindex])))\n",
    "            compressed_row = np.ndarray.flatten(self.layers[self.bottleneck_layer_no].output)\n",
    "            output_rows.append(compressed_row)\n",
    "        return np.stack(output_rows)\n",
    "\n",
    "    def forward_propogation(self, x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # print(layer.layerno)\n",
    "            if layer.layerno == 0:\n",
    "                layer.input = x\n",
    "                if layer.activation_function:\n",
    "                    layer.output = activation(layer.input,\n",
    "                                              layer.activation_function)\n",
    "                else:\n",
    "                    layer.output = x\n",
    "            else:\n",
    "                layer.input = np.dot(\n",
    "                    self.layers[layer.layerno - 1].output, self.weights[\n",
    "                        layer.layerno - 1]) + self.bias[layer.layerno - 1]\n",
    "                layer.output = activation(layer.input,\n",
    "                                          layer.activation_function)\n",
    "#                 if (layer.layerno + 1) < len(self.layers):\n",
    "#                     self.layers[layer.layerno + 1].input = layer.output\n",
    "# print(layer.input)\n",
    "#  print(layer.output)\n",
    "\n",
    "    def error(self, predicted, actual):\n",
    "        return np.sum(np.power((np.array(predicted) - np.array(actual)), 2))\n",
    "\n",
    "    def error_der(self, predicted, actual):\n",
    "        return 2 * (predicted - actual)\n",
    "\n",
    "    def error2(self, predicted, actual):\n",
    "        epsilon = 1e-12\n",
    "        predictions = np.clip(predicted, epsilon, 1. - epsilon)\n",
    "        N = predictions.shape[1]\n",
    "        ce = -np.sum(actual * np.log(predictions + 1e-9)) / N\n",
    "        return ce\n",
    "\n",
    "    def error2_der(self, predicted, actual):\n",
    "        return -1 * ((actual * (1 / predicted)) + (1 - actual) * (\n",
    "            (1 / (1 - predicted))))\n",
    "\n",
    "    def weights_behind(self, layer_):\n",
    "        return self.weights[layer_.layerno - 1]\n",
    "\n",
    "    def weights_ahead(self, layer_):\n",
    "        return self.weights[layer_.layerno]\n",
    "\n",
    "    def layer_behind(self, layer_):\n",
    "        return self.layers[layer_.layerno - 1]\n",
    "\n",
    "    def layer_ahead(self, layer_):\n",
    "        return self.layers[layer_.layerno + 1]\n",
    "\n",
    "    def backward_propogation(self, y):\n",
    "\n",
    "        stored = np.float128(1.0)\n",
    "\n",
    "        for curr_layer in self.layers[::-1]:\n",
    "            if curr_layer.layerno == 0:\n",
    "                continue\n",
    "            if curr_layer.layerno == len(self.layers) - 1:\n",
    "\n",
    "                stored = np.dot(self.error(curr_layer.output, y), stored)\n",
    "                curr_layer.error = stored\n",
    "                # print(\"error\",curr_layer.error)\n",
    "\n",
    "                curr_layer.derivative_op = self.error_der(curr_layer.output, y)\n",
    "                #  print(curr_layer.derivative_op,curr_layer.derivative_op.shape)\n",
    "\n",
    "                curr_layer.derivative_act = activation_der(\n",
    "                    curr_layer.input, curr_layer.activation_function)\n",
    "                #  print(curr_layer.derivative_act,curr_layer.derivative_act.shape)\n",
    "\n",
    "                curr_layer.k_product = curr_layer.derivative_op * curr_layer.derivative_act\n",
    "                # print(curr_layer.k_product,curr_layer.k_product.shape)\n",
    "\n",
    "                #curr_layer.k_product = curr_layer.k_product.reshape(1,curr_layer.derivative_act.shape[0])\n",
    "                curr_layer.derivative_wt = np.dot(\n",
    "                    (self.layers[curr_layer.layerno - 1].output).T,\n",
    "                    curr_layer.k_product)\n",
    "\n",
    "                #self.weights[curr_layer.layerno - 1] -= self.learning_rate * curr_layer.derivative_wt\n",
    "\n",
    "            else:\n",
    "                #   print(curr_layer.layerno)\n",
    "                curr_layer.error = None\n",
    "                curr_layer.derivative_act = activation_der(\n",
    "                    curr_layer.input, curr_layer.activation_function)\n",
    "                curr_layer.derivative_op = np.dot(\n",
    "                    self.layers[curr_layer.layerno + 1].k_product,\n",
    "                    (self.weights_ahead(curr_layer)).T)\n",
    "                curr_layer.k_product = curr_layer.derivative_op * curr_layer.derivative_act\n",
    "                #if curr_layer.layerno != 1:\n",
    "                curr_layer.derivative_wt = np.dot(\n",
    "                    (self.layer_behind(curr_layer).output).T,\n",
    "                    curr_layer.k_product)\n",
    "\n",
    "\n",
    "#                 else:\n",
    "#                     curr_layer.derivative_wt = np.dot( (self.layer_behind(curr_layer).input).T , curr_layer.k_product)\n",
    "\n",
    "        for w_no, weight in enumerate(self.weights):\n",
    "            self.weights[w_no] -= self.learning_rate * (\n",
    "                self.layers[w_no + 1].derivative_wt)\n",
    "            self.bias[w_no] -= self.learning_rate * (\n",
    "                np.sum(self.layers[w_no + 1].k_product , axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Linear 3 layer autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = neural_net(3,0.00001,200,100)\n",
    "net.add_layer(29,\"linear\")\n",
    "net.add_layer(14,\"linear\")\n",
    "net.add_layer(29,\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np_version = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Error:  30.89370238287123699\n",
      "epoch:  1\n",
      "Error:  18.88346168870672365\n",
      "epoch:  2\n",
      "Error:  15.444148213563468005\n",
      "epoch:  3\n",
      "Error:  13.315884259962382252\n",
      "epoch:  4\n",
      "Error:  11.585813993056092459\n",
      "epoch:  5\n",
      "Error:  10.062287021187208455\n",
      "epoch:  6\n",
      "Error:  8.560207683041811423\n",
      "epoch:  7\n",
      "Error:  7.2703333974826643833\n",
      "epoch:  8\n",
      "Error:  6.2381989297047855834\n",
      "epoch:  9\n",
      "Error:  5.524406161102730432\n",
      "epoch:  10\n",
      "Error:  5.0195530048852745903\n",
      "epoch:  11\n",
      "Error:  4.581902918152702502\n",
      "epoch:  12\n",
      "Error:  4.1701866998185729385\n",
      "epoch:  13\n",
      "Error:  3.800893412215946057\n",
      "epoch:  14\n",
      "Error:  3.4985570581359584981\n",
      "epoch:  15\n",
      "Error:  3.3018367825697557412\n",
      "epoch:  16\n",
      "Error:  3.200999388422801665\n",
      "epoch:  17\n",
      "Error:  3.1501360593630350416\n",
      "epoch:  18\n",
      "Error:  3.119279805600072924\n",
      "epoch:  19\n",
      "Error:  3.0964817691301788855\n",
      "epoch:  20\n",
      "Error:  3.077597563940607877\n",
      "epoch:  21\n",
      "Error:  3.0611298197203804688\n",
      "epoch:  22\n",
      "Error:  3.0464187786054668736\n",
      "epoch:  23\n",
      "Error:  3.0330866932956663798\n",
      "epoch:  24\n",
      "Error:  3.0208718562587960218\n",
      "epoch:  25\n",
      "Error:  3.0095755679582101472\n",
      "epoch:  26\n",
      "Error:  2.9990417819405566697\n",
      "epoch:  27\n",
      "Error:  2.9891467871078415428\n",
      "epoch:  28\n",
      "Error:  2.979792424343376681\n",
      "epoch:  29\n",
      "Error:  2.9709009319332585653\n",
      "epoch:  30\n",
      "Error:  2.9624107928288923343\n",
      "epoch:  31\n",
      "Error:  2.9542733523004041933\n",
      "epoch:  32\n",
      "Error:  2.9464500684443229797\n",
      "epoch:  33\n",
      "Error:  2.9389102998422185701\n",
      "epoch:  34\n",
      "Error:  2.9316295399117162676\n",
      "epoch:  35\n",
      "Error:  2.9245880220282893405\n",
      "epoch:  36\n",
      "Error:  2.9177696251360249991\n",
      "epoch:  37\n",
      "Error:  2.9111610221730176997\n",
      "epoch:  38\n",
      "Error:  2.9047510211425176883\n",
      "epoch:  39\n",
      "Error:  2.8985300588704023606\n",
      "epoch:  40\n",
      "Error:  2.892489814084157017\n",
      "epoch:  41\n",
      "Error:  2.8866229137384316465\n",
      "epoch:  42\n",
      "Error:  2.88092271135935923\n",
      "epoch:  43\n",
      "Error:  2.8753831210092124745\n",
      "epoch:  44\n",
      "Error:  2.8699984937434750893\n",
      "epoch:  45\n",
      "Error:  2.864763526499436723\n",
      "epoch:  46\n",
      "Error:  2.8596731954633033677\n",
      "epoch:  47\n",
      "Error:  2.8547227078623656047\n",
      "epoch:  48\n",
      "Error:  2.8499074674502581281\n",
      "epoch:  49\n",
      "Error:  2.8452230501103598958\n",
      "epoch:  50\n",
      "Error:  2.840665186815254898\n",
      "epoch:  51\n",
      "Error:  2.8362297518756679167\n",
      "epoch:  52\n",
      "Error:  2.83191275490455858\n",
      "epoch:  53\n",
      "Error:  2.8277103353350585497\n",
      "epoch:  54\n",
      "Error:  2.8236187586242855233\n",
      "epoch:  55\n",
      "Error:  2.8196344135169665902\n",
      "epoch:  56\n",
      "Error:  2.8157538099143769412\n",
      "epoch:  57\n",
      "Error:  2.8119735770330028847\n",
      "epoch:  58\n",
      "Error:  2.808290461635278219\n",
      "epoch:  59\n",
      "Error:  2.8047013261922139422\n",
      "epoch:  60\n",
      "Error:  2.8012031468915710051\n",
      "epoch:  61\n",
      "Error:  2.7977930114465192656\n",
      "epoch:  62\n",
      "Error:  2.7944681166875226766\n",
      "epoch:  63\n",
      "Error:  2.7912257659405741359\n",
      "epoch:  64\n",
      "Error:  2.7880633662076166601\n",
      "epoch:  65\n",
      "Error:  2.7849784251736230325\n",
      "epoch:  66\n",
      "Error:  2.7819685480691420546\n",
      "epoch:  67\n",
      "Error:  2.7790314344192998128\n",
      "epoch:  68\n",
      "Error:  2.7761648747103392048\n",
      "epoch:  69\n",
      "Error:  2.7733667470035710295\n",
      "epoch:  70\n",
      "Error:  2.7706350135247854905\n",
      "epoch:  71\n",
      "Error:  2.7679677172545302803\n",
      "epoch:  72\n",
      "Error:  2.7653629785419720755\n",
      "epoch:  73\n",
      "Error:  2.7628189917622314512\n",
      "epoch:  74\n",
      "Error:  2.7603340220341579208\n",
      "epoch:  75\n",
      "Error:  2.757906402012893102\n",
      "epoch:  76\n",
      "Error:  2.7555345287689123066\n",
      "epoch:  77\n",
      "Error:  2.75321686076301586\n",
      "epoch:  78\n",
      "Error:  2.750951914924448238\n",
      "epoch:  79\n",
      "Error:  2.7487382638375806414\n",
      "epoch:  80\n",
      "Error:  2.7465745330407593063\n",
      "epoch:  81\n",
      "Error:  2.7444593984395515343\n",
      "epoch:  82\n",
      "Error:  2.7423915838353008355\n",
      "epoch:  83\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-201fc6ddebea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_np_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_np_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-219296f35617>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     np.array(x[rowindex]).reshape(1, len(x[rowindex])))\n\u001b[1;32m    224\u001b[0m                 self.backward_propogation(\n\u001b[0;32m--> 225\u001b[0;31m                     np.array(y[rowindex]).reshape(1, len(y[rowindex])))\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0merror_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-219296f35617>\u001b[0m in \u001b[0;36mbackward_propogation\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerno\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_product\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     (self.weights_ahead(curr_layer)).T)\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0mcurr_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative_op\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurr_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative_act\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;31m#if curr_layer.layerno != 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 curr_layer.derivative_wt = np.dot(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.fit(data_np_version,data_np_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23374411, -0.49313465,  0.00335603, -0.03068531, -0.15745575,\n",
       "         0.00272219, -0.02347751, -0.01223557, -0.02593485, -0.03105481,\n",
       "        -0.88404291, -0.31824075, -0.66918424, -0.6545484 , -0.37264622,\n",
       "        -0.34713708,  0.85244285, -0.30867412,  1.20071923, -0.65388317,\n",
       "         1.03960739,  1.09619706, -0.68566847, -0.25497931,  0.40126038,\n",
       "        -0.68336932, -0.6753196 , -0.4103169 , -0.37528644]],\n",
       "      dtype=float128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[-2].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11453594,  1.08986369, -0.01009217, -0.03981825, -0.09095369,\n",
       "       -0.02632138, -0.02193782, -0.02180098, -0.02791524, -0.04408631,\n",
       "        0.52738518, -0.34125155,  1.60156754,  1.60618312, -0.37313313,\n",
       "       -0.37394367, -1.46052423,  0.09709138, -0.37495017,  0.73293232,\n",
       "       -1.01441809, -1.13725095, -0.01654114, -0.47971213, -0.28900005,\n",
       "        1.61007621,  1.62017237, -0.38606912, -0.37497461])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np_version[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"weights_for_linear_structure\",net.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.weights = np.load(\"weights_for_linear_structure.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_datamatrix = net.get_compressed_datamatrix(data_np_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.63123089, -1.67182321,  0.74316101, ...,  1.89135216,\n",
       "         0.25238787, -1.12352115],\n",
       "       [-3.2981409 ,  0.34983649,  1.22945096, ...,  3.04589628,\n",
       "        -1.39226853, -0.13902169],\n",
       "       [-2.6928459 , -1.75968753,  0.74508756, ...,  1.79183609,\n",
       "         0.16612739, -1.49790274],\n",
       "       ...,\n",
       "       [-2.54002801, -5.34925847, 12.00869093, ...,  6.81033694,\n",
       "         3.60860287, -5.0550234 ],\n",
       "       [ 0.6348558 ,  0.4745977 , -0.02190007, ...,  2.69437641,\n",
       "        -1.06930793,  1.35972388],\n",
       "       [ 0.50273287, -1.0819395 ,  0.3564614 , ...,  0.82724507,\n",
       "         3.57945796, -1.58508144]], dtype=float128)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_datamatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### B. Non-linear 5 layer autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">- relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = neural_net(5,0.00001,200,100)\n",
    "net.add_layer(29,\"linear\")\n",
    "net.add_layer(20,\"relu\")\n",
    "net.add_layer(14,\"relu\")\n",
    "net.add_layer(20,\"relu\")\n",
    "net.add_layer(29,\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'neural_net' object has no attribute 'error_der2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-201fc6ddebea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_np_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_np_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-233-a86f4960c6e7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    221\u001b[0m                     np.array(x[rowindex]).reshape(1, len(x[rowindex])))\n\u001b[1;32m    222\u001b[0m                 self.backward_propogation(\n\u001b[0;32m--> 223\u001b[0;31m                     np.array(y[rowindex]).reshape(1, len(y[rowindex])))\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0merror_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-233-a86f4960c6e7>\u001b[0m in \u001b[0;36mbackward_propogation\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;31m# print(\"error\",curr_layer.error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0mcurr_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_der2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0;31m#  print(curr_layer.derivative_op,curr_layer.derivative_op.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'neural_net' object has no attribute 'error_der2'"
     ]
    }
   ],
   "source": [
    "net.fit(data_np_version,data_np_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(\"weights_for_non_linear_structure_relu_5\",net.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">- Relu-sigmoid=relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Error:  29.135349356184182316\n",
      "epoch:  1\n",
      "Error:  25.356440338380253161\n",
      "epoch:  2\n",
      "Error:  16.960402422379426546\n",
      "epoch:  3\n",
      "Error:  15.552930840099195896\n",
      "epoch:  4\n",
      "Error:  14.373908622129548366\n",
      "epoch:  5\n",
      "Error:  14.133240807982991121\n",
      "epoch:  6\n",
      "Error:  13.110231244048092821\n",
      "epoch:  7\n",
      "Error:  12.871846058295471896\n",
      "epoch:  8\n",
      "Error:  12.836036410982032077\n",
      "epoch:  9\n",
      "Error:  12.7864505338658876075\n"
     ]
    }
   ],
   "source": [
    "net = neural_net(5,0.0005,10,100)\n",
    "net.add_layer(29,\"linear\")\n",
    "net.add_layer(18,\"relu\")\n",
    "net.add_layer(14,\"sigmoid\")\n",
    "net.add_layer(18,\"relu\")\n",
    "net.add_layer(29,\"linear\")\n",
    "\n",
    "net.fit(data_np_version,data_np_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Error:  29.228945897844533302\n",
      "epoch:  1\n",
      "Error:  29.103294586926119624\n",
      "epoch:  2\n",
      "Error:  29.095306655088073773\n",
      "epoch:  3\n",
      "Error:  29.087647884524563855\n",
      "epoch:  4\n",
      "Error:  29.079958764659424779\n",
      "epoch:  5\n",
      "Error:  29.068379531329705054\n",
      "epoch:  6\n",
      "Error:  28.96776348835732333\n",
      "epoch:  7\n",
      "Error:  24.325424882234323695\n",
      "epoch:  8\n",
      "Error:  22.335597498481559574\n",
      "epoch:  9\n",
      "Error:  22.117956220124864952\n",
      "epoch:  10\n",
      "Error:  20.344638202857145208\n",
      "epoch:  11\n",
      "Error:  18.118363015242473767\n",
      "epoch:  12\n",
      "Error:  17.818726470511669918\n",
      "epoch:  13\n",
      "Error:  17.505360329548569284\n",
      "epoch:  14\n",
      "Error:  17.056336587573878405\n",
      "epoch:  15\n",
      "Error:  16.643507811880237852\n",
      "epoch:  16\n",
      "Error:  16.375245759744334098\n",
      "epoch:  17\n",
      "Error:  16.069867305004472158\n",
      "epoch:  18\n",
      "Error:  15.4042923640097917486\n",
      "epoch:  19\n",
      "Error:  14.781216044706047723\n",
      "epoch:  20\n",
      "Error:  14.458122263803927462\n",
      "epoch:  21\n",
      "Error:  14.108210245736962171\n",
      "epoch:  22\n",
      "Error:  13.656795761151586579\n",
      "epoch:  23\n",
      "Error:  13.009626503882803941\n",
      "epoch:  24\n",
      "Error:  12.588519313817437949\n",
      "epoch:  25\n",
      "Error:  12.3259711110237921315\n",
      "epoch:  26\n",
      "Error:  12.105076345890793792\n",
      "epoch:  27\n",
      "Error:  11.886373686851745893\n",
      "epoch:  28\n",
      "Error:  11.6459714741938349086\n",
      "epoch:  29\n",
      "Error:  11.379751131658128763\n",
      "epoch:  30\n",
      "Error:  11.1008623518543487405\n",
      "epoch:  31\n",
      "Error:  10.835884532562216377\n",
      "epoch:  32\n",
      "Error:  10.610018413475879462\n",
      "epoch:  33\n",
      "Error:  10.434275885795764633\n",
      "epoch:  34\n",
      "Error:  10.2834950029290838076\n",
      "epoch:  35\n",
      "Error:  10.155937102709021463\n",
      "epoch:  36\n",
      "Error:  10.04830495835455422\n",
      "epoch:  37\n",
      "Error:  9.940052486866349524\n",
      "epoch:  38\n",
      "Error:  9.8094745642798890405\n",
      "epoch:  39\n",
      "Error:  9.646386553384662388\n",
      "epoch:  40\n",
      "Error:  9.478732039337035676\n",
      "epoch:  41\n",
      "Error:  9.342284643536942976\n",
      "epoch:  42\n",
      "Error:  9.244115855284410998\n",
      "epoch:  43\n",
      "Error:  9.134546984151772071\n",
      "epoch:  44\n",
      "Error:  9.025124957008797807\n",
      "epoch:  45\n",
      "Error:  8.931242746223471662\n",
      "epoch:  46\n",
      "Error:  8.828553553163288568\n",
      "epoch:  47\n",
      "Error:  8.7263689172951249265\n",
      "epoch:  48\n",
      "Error:  8.650437014203159691\n",
      "epoch:  49\n",
      "Error:  8.552583711938604816\n",
      "epoch:  50\n",
      "Error:  8.4759375106687333875\n",
      "epoch:  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  8.550195768445850642\n",
      "epoch:  52\n",
      "Error:  8.407767104293403267\n",
      "epoch:  53\n",
      "Error:  8.205852924472368121\n",
      "epoch:  54\n",
      "Error:  8.079726795208907779\n",
      "epoch:  55\n",
      "Error:  7.9383196730226132576\n",
      "epoch:  56\n",
      "Error:  7.8217778956989488467\n",
      "epoch:  57\n",
      "Error:  7.6945293266252294644\n",
      "epoch:  58\n",
      "Error:  7.5803299828198306624\n",
      "epoch:  59\n",
      "Error:  7.4756914444168588284\n",
      "epoch:  60\n",
      "Error:  7.3850699105304403957\n",
      "epoch:  61\n",
      "Error:  7.3586425212581157277\n",
      "epoch:  62\n",
      "Error:  7.3403454234741798362\n",
      "epoch:  63\n",
      "Error:  7.2383970492787661584\n",
      "epoch:  64\n",
      "Error:  7.1679632852628905053\n",
      "epoch:  65\n",
      "Error:  7.1513658672777143683\n",
      "epoch:  66\n",
      "Error:  7.08053278652336964\n",
      "epoch:  67\n",
      "Error:  7.008599462520247694\n",
      "epoch:  68\n",
      "Error:  6.9730721399097825644\n",
      "epoch:  69\n",
      "Error:  6.9497462210898335805\n",
      "epoch:  70\n",
      "Error:  6.8842614907404966764\n",
      "epoch:  71\n",
      "Error:  6.81061619512339941\n",
      "epoch:  72\n",
      "Error:  6.7431342369162143484\n",
      "epoch:  73\n",
      "Error:  6.7013329660661630077\n",
      "epoch:  74\n",
      "Error:  6.6657037237498236153\n",
      "epoch:  75\n",
      "Error:  6.6355168977070753825\n",
      "epoch:  76\n",
      "Error:  6.822198909022591371\n",
      "epoch:  77\n",
      "Error:  6.771773501292932301\n",
      "epoch:  78\n",
      "Error:  6.6920646343501253846\n",
      "epoch:  79\n",
      "Error:  6.573680191851787636\n",
      "epoch:  80\n",
      "Error:  6.5131111167106279206\n",
      "epoch:  81\n",
      "Error:  6.468467166755003791\n",
      "epoch:  82\n",
      "Error:  6.423408500179016133\n",
      "epoch:  83\n",
      "Error:  6.380696367177955919\n",
      "epoch:  84\n",
      "Error:  6.3473447026928490004\n",
      "epoch:  85\n",
      "Error:  6.2940992973299028576\n",
      "epoch:  86\n",
      "Error:  6.2418520031080415075\n",
      "epoch:  87\n",
      "Error:  6.1947465330545052986\n",
      "epoch:  88\n",
      "Error:  6.15011973666227607\n",
      "epoch:  89\n",
      "Error:  6.1436548655793863107\n",
      "epoch:  90\n",
      "Error:  6.1338497616150586683\n",
      "epoch:  91\n",
      "Error:  6.077763579485607979\n",
      "epoch:  92\n",
      "Error:  6.0155850081779379175\n",
      "epoch:  93\n",
      "Error:  6.0143037009684938384\n",
      "epoch:  94\n",
      "Error:  5.964592370417653744\n",
      "epoch:  95\n",
      "Error:  5.896943145743536701\n",
      "epoch:  96\n",
      "Error:  5.899231114331143245\n",
      "epoch:  97\n",
      "Error:  5.766105628042959485\n",
      "epoch:  98\n",
      "Error:  5.7098355712022458683\n",
      "epoch:  99\n",
      "Error:  5.650239799184621097\n",
      "epoch:  100\n",
      "Error:  5.6046777787514812414\n",
      "epoch:  101\n",
      "Error:  5.6073260543074428973\n",
      "epoch:  102\n",
      "Error:  5.536780461789884576\n",
      "epoch:  103\n",
      "Error:  5.473890010048018828\n",
      "epoch:  104\n",
      "Error:  5.422570118257406624\n",
      "epoch:  105\n",
      "Error:  5.3824566559521464363\n",
      "epoch:  106\n",
      "Error:  5.337417391056840129\n",
      "epoch:  107\n",
      "Error:  5.397793420544864158\n",
      "epoch:  108\n",
      "Error:  6.3269896139323221164\n",
      "epoch:  109\n",
      "Error:  5.6780368853404264867\n",
      "epoch:  110\n",
      "Error:  5.6136997295312616204\n",
      "epoch:  111\n",
      "Error:  5.551422402497751181\n",
      "epoch:  112\n",
      "Error:  5.5985162523998779236\n",
      "epoch:  113\n",
      "Error:  5.509253021050562873\n",
      "epoch:  114\n",
      "Error:  5.5579854920395651394\n",
      "epoch:  115\n",
      "Error:  5.62984876436339353\n",
      "epoch:  116\n",
      "Error:  5.5385290095921716107\n",
      "epoch:  117\n",
      "Error:  5.4546686159917812595\n",
      "epoch:  118\n",
      "Error:  5.3969255329401673573\n",
      "epoch:  119\n",
      "Error:  5.396165148005949497\n",
      "epoch:  120\n",
      "Error:  5.391859526879188932\n",
      "epoch:  121\n",
      "Error:  5.3444590773015585427\n",
      "epoch:  122\n",
      "Error:  5.3094694057054517265\n",
      "epoch:  123\n",
      "Error:  5.2839519026593957194\n",
      "epoch:  124\n",
      "Error:  5.282662394705730637\n",
      "epoch:  125\n",
      "Error:  5.212344087505700755\n",
      "epoch:  126\n",
      "Error:  5.1744940383680852474\n",
      "epoch:  127\n",
      "Error:  5.1362514943867031434\n",
      "epoch:  128\n",
      "Error:  5.0944104722394128906\n",
      "epoch:  129\n",
      "Error:  5.0883431123323102922\n",
      "epoch:  130\n",
      "Error:  5.0713153809455219783\n",
      "epoch:  131\n",
      "Error:  5.0008373017428077306\n",
      "epoch:  132\n",
      "Error:  4.9557021782817551707\n",
      "epoch:  133\n",
      "Error:  4.9357924140742693605\n",
      "epoch:  134\n",
      "Error:  5.2583033881771472015\n",
      "epoch:  135\n",
      "Error:  5.1585838869646502016\n",
      "epoch:  136\n",
      "Error:  5.1120155719765625973\n",
      "epoch:  137\n",
      "Error:  5.0821742379915192784\n",
      "epoch:  138\n",
      "Error:  5.06467766793916301\n",
      "epoch:  139\n",
      "Error:  5.0274039292701646316\n",
      "epoch:  140\n",
      "Error:  5.0000320012461835764\n",
      "epoch:  141\n",
      "Error:  4.9449627744098375065\n",
      "epoch:  142\n",
      "Error:  5.0070693422076910533\n",
      "epoch:  143\n",
      "Error:  5.0452087439366107863\n",
      "epoch:  144\n",
      "Error:  5.0834436282016219268\n",
      "epoch:  145\n",
      "Error:  5.049983384564320002\n",
      "epoch:  146\n",
      "Error:  4.965645470484135563\n",
      "epoch:  147\n",
      "Error:  4.894225118761201761\n",
      "epoch:  148\n",
      "Error:  4.8327400445836328335\n",
      "epoch:  149\n",
      "Error:  4.760825812285499686\n",
      "epoch:  150\n",
      "Error:  4.8165677410757352403\n",
      "epoch:  151\n",
      "Error:  4.714162805655538761\n",
      "epoch:  152\n",
      "Error:  4.667575373638383584\n",
      "epoch:  153\n",
      "Error:  4.6033016775004659544\n",
      "epoch:  154\n",
      "Error:  4.5502988587534202074\n",
      "epoch:  155\n",
      "Error:  4.5452566136359677496\n",
      "epoch:  156\n",
      "Error:  4.495881962531823532\n",
      "epoch:  157\n",
      "Error:  4.4877086410920736014\n",
      "epoch:  158\n",
      "Error:  4.451770410083881299\n",
      "epoch:  159\n",
      "Error:  4.4043222345395764317\n",
      "epoch:  160\n",
      "Error:  4.4114806186176807132\n",
      "epoch:  161\n",
      "Error:  4.370821561249079405\n",
      "epoch:  162\n",
      "Error:  4.327090923385750117\n",
      "epoch:  163\n",
      "Error:  4.3326739705174251173\n",
      "epoch:  164\n",
      "Error:  4.445052517431790509\n",
      "epoch:  165\n",
      "Error:  4.430664563857667942\n",
      "epoch:  166\n",
      "Error:  4.351445255587279062\n",
      "epoch:  167\n",
      "Error:  4.309069683155418258\n",
      "epoch:  168\n",
      "Error:  4.4333837896857066618\n",
      "epoch:  169\n",
      "Error:  4.666622737241472429\n",
      "epoch:  170\n",
      "Error:  4.4047278286062261387\n",
      "epoch:  171\n",
      "Error:  4.3584126464305384158\n",
      "epoch:  172\n",
      "Error:  4.188335502992587676\n",
      "epoch:  173\n",
      "Error:  4.927027424703009852\n",
      "epoch:  174\n",
      "Error:  4.7597675642926714607\n",
      "epoch:  175\n",
      "Error:  5.82142083066696143\n",
      "epoch:  176\n",
      "Error:  5.6661103053373759082\n",
      "epoch:  177\n",
      "Error:  5.6969349967296777693\n",
      "epoch:  178\n",
      "Error:  5.745475250406719644\n",
      "epoch:  179\n",
      "Error:  5.3891603482240303413\n",
      "epoch:  180\n",
      "Error:  5.2999051345129766693\n",
      "epoch:  181\n",
      "Error:  5.192059533112579539\n",
      "epoch:  182\n",
      "Error:  5.0759202158639404644\n",
      "epoch:  183\n",
      "Error:  5.148157112411562708\n",
      "epoch:  184\n",
      "Error:  5.0087183739703593868\n",
      "epoch:  185\n",
      "Error:  5.039076388826929185\n",
      "epoch:  186\n",
      "Error:  4.9795643913684818935\n",
      "epoch:  187\n",
      "Error:  5.2904543751374397305\n",
      "epoch:  188\n",
      "Error:  5.115884190693060527\n",
      "epoch:  189\n",
      "Error:  5.054598454917115385\n",
      "epoch:  190\n",
      "Error:  4.9897923405566068132\n",
      "epoch:  191\n",
      "Error:  4.863695109217236117\n",
      "epoch:  192\n",
      "Error:  4.7771909718765792788\n",
      "epoch:  193\n",
      "Error:  4.731856674220865505\n",
      "epoch:  194\n",
      "Error:  4.6866664631975162645\n",
      "epoch:  195\n",
      "Error:  4.6631621883243848776\n",
      "epoch:  196\n",
      "Error:  5.868168415889871716\n",
      "epoch:  197\n",
      "Error:  4.7669195451674194917\n",
      "epoch:  198\n",
      "Error:  4.403191862673517915\n",
      "epoch:  199\n",
      "Error:  4.3461956842696315467\n"
     ]
    }
   ],
   "source": [
    "net = neural_net(5,0.0005,200,100)\n",
    "net.add_layer(29,\"linear\")\n",
    "net.add_layer(18,\"sigmoid\")\n",
    "net.add_layer(14,\"sigmoid\")\n",
    "net.add_layer(18,\"sigmoid\")\n",
    "net.add_layer(29,\"linear\")\n",
    "\n",
    "net.fit(data_np_version,data_np_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Non linear 7 layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Error:  29.199021449523665602\n",
      "epoch:  1\n",
      "Error:  29.10483233026653815\n",
      "epoch:  2\n",
      "Error:  29.084143556034504657\n",
      "epoch:  3\n",
      "Error:  29.068691456257087323\n",
      "epoch:  4\n",
      "Error:  26.76896553640453552\n",
      "epoch:  5\n",
      "Error:  18.909447023874307744\n",
      "epoch:  6\n",
      "Error:  18.482681028882465125\n",
      "epoch:  7\n",
      "Error:  15.80447381098963283\n",
      "epoch:  8\n",
      "Error:  14.257510160917040319\n",
      "epoch:  9\n",
      "Error:  12.880951105362203367\n"
     ]
    }
   ],
   "source": [
    "net = neural_net(7,0.001,10,100)\n",
    "net.add_layer(29,\"linear\")\n",
    "net.add_layer(20,\"relu\")\n",
    "net.add_layer(16,\"relu\")\n",
    "net.add_layer(14,\"sigmoid\")\n",
    "net.add_layer(16,\"relu\")\n",
    "net.add_layer(20,\"relu\")\n",
    "net.add_layer(29,\"linear\")\n",
    "\n",
    "net.fit(data_np_version,data_np_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - means on reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ecludian(row1,row2):\n",
    "    dist = 0.0\n",
    "    dist += math.sqrt(sum((np.array(row1)-np.array(row2))**2))\n",
    "    return dist\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "def assigncluster(centroid , row):\n",
    "    mintill = 9999999999\n",
    "    clust = -1\n",
    "    for i in centroid:\n",
    "        dist  = ecludian(row,i)\n",
    "        if(dist < mintill):\n",
    "            mintill = dist\n",
    "            clust = i\n",
    "    return clust\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "def recalculate_centroid(clusters,data):\n",
    "    newcentroid = []\n",
    "    for i in clusters.keys():\n",
    "        sumc = [0]*len(clusters[i][0])\n",
    "        for j in range(len(clusters[i])):\n",
    "            #print(clusters[i],\"clusteri\")\n",
    "            #print(clusters[i][j],\"what is this\")\n",
    "            sumc = sumc + np.array(clusters[i][j])  #data.loc[index.get_loc(clusters[i][j] )]\n",
    "            #print(sumc,\"sums\")                       \n",
    "        newcentroid.append(tuple(sumc/len(clusters[i])))\n",
    "    return newcentroid\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "def getrandomcentorid(k,data):\n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rand = random.randint(0,len(data)-1)\n",
    "        randval = tuple(data.loc[rand].values)\n",
    "        while randval in centroids:\n",
    "            randval = tuple(data.loc[random.randint(0,len(data)-1)])\n",
    "        centroids.append(randval)\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "def buildcluster(k,data,centroids):\n",
    "    clu = {}\n",
    "    for c in centroids:\n",
    "        clu[c] = []\n",
    "    for i,row in data.iterrows():\n",
    "        rown = tuple(row)\n",
    "        #print(assigncluster(centroids,rown))\n",
    "        clu[assigncluster(centroids,rown)].append(rown)\n",
    "        #print(rown)\n",
    "    return clu\n",
    "\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "def converge(cone,ctwo,tolerance,k):\n",
    "    countofpos = 0\n",
    "    for i in range(k):\n",
    "        dist = ecludian(cone[i],ctwo[i])\n",
    "        if(dist <= tolerance):\n",
    "            countofpos += 1\n",
    "    if(countofpos == k):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "def kmeans(data,k):\n",
    "    centroid = getrandomcentorid(k,data)\n",
    "    c1 = deepcopy(centroid)\n",
    "    \n",
    "    #print(c1)\n",
    "    #print(len(c1))\n",
    "    #print(assigncluster(c1,c1[0]),\"assigned\")\n",
    "    #print(c1)\n",
    "    clusters = buildcluster(k,data,c1)\n",
    "    #print(clusters)\n",
    "    #print(len(clusters.keys()),\"keys\")\n",
    "    newcentroid = recalculate_centroid(clusters,data)\n",
    "    iterations = 0\n",
    "    while not converge(c1,newcentroid,0,k) :\n",
    "        print(iterations)\n",
    "        c1 = newcentroid\n",
    "        clusters = buildcluster(k,data,c1)\n",
    "        newcentroid = recalculate_centroid(clusters,data)\n",
    "        iterations += 1\n",
    "    return clusters\n",
    "    print(\"final clusters\",clusters)\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "#data_for_kmeans = pd.DataFrame(pro_x)\n",
    "#data_for_kmeans = (data_for_kmeans - data_for_kmeans.mean())/data_for_kmeans.std()\n",
    "# print(data_for_kmeans)\n",
    "# data_for_kmeans.describe()\n",
    "#data_for_kmeans.columns = list(data)\n",
    "# data_for_kmeans = data_for_kmeans\n",
    "# clusters = kmeans(data_for_kmeans,5)\n",
    "\n",
    "# clusterone = clusters[list(clusters.keys())[4]]\n",
    "# results = []\n",
    "# index = -1\n",
    "# for i in clusterone:\n",
    "#     for no,j in original_data.iterrows():\n",
    "#         if tuple(j) == i:\n",
    "#             index = no\n",
    "#             break\n",
    "#     results.append(total_y_values.iloc[index])\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "def getdistances(data,centers,i):\n",
    "    return  np.linalg.norm(data - centers[i], axis=1)\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "def geterror(centernew,centerold):\n",
    "    return np.linalg.norm(centernew - centerold)\n",
    "\n",
    "\n",
    "# In[88]:\n",
    "\n",
    "\n",
    "def getnewcenters(k,data,centers_new,clusters):\n",
    "    for i in range(k):\n",
    "        centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "    return centers_new\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_final(k,pro_x):\n",
    "    n = pro_x.shape[0]\n",
    "    data = pro_x\n",
    "    #print(pro_x.shape[1])\n",
    "\n",
    "\n",
    "    centers = np.random.randn(k,pro_x.shape[1])\n",
    "    #print(centers)\n",
    "    centers_old = np.zeros(centers.shape) \n",
    "    #print(centers_old.shape)\n",
    "    centers_new = deepcopy(centers) \n",
    "\n",
    "    print(data.shape)\n",
    "    clusters = np.zeros(n)\n",
    "    print()\n",
    "    distances = np.zeros((n,k))\n",
    "    #print(distances.shape)\n",
    "\n",
    "    error = geterror(centers_new,centers_old)\n",
    "\n",
    "\n",
    "    while error != 0:\n",
    "\n",
    "        for i in range(k):\n",
    "            distances[:,i] = getdistances(data,centers,i)\n",
    "\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "\n",
    "        centers_old = deepcopy(centers_new)\n",
    "\n",
    "        centers_new = getnewcenters(k,data,centers_new,clusters)\n",
    "\n",
    "\n",
    "        error = geterror(centers_new,centers_old)\n",
    "\n",
    "    purity = []\n",
    "    output_labels = []\n",
    "\n",
    "    for i in range(k):\n",
    "        output_labels.append([])\n",
    "\n",
    "    total_for_k_means = np.array(total_y_values)\n",
    "    for i in range(n):\n",
    "        output_labels[clusters[i]].append(total_y_values[i])\n",
    "    return output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24998, 14)\n",
      "\n",
      "cluster :  0 , Maximum label present :  normal , No of times:  878 , Purity : 0.9184100418410042\n",
      "cluster :  1 , Maximum label present :  dos , No of times:  8437 , Purity : 0.6418898356664637\n",
      "cluster :  2 , Maximum label present :  probe , No of times:  1 , Purity : 1.0\n",
      "cluster :  3 , Maximum label present :  normal , No of times:  7850 , Purity : 0.8154149787057234\n",
      "cluster :  4 , Maximum label present :  probe , No of times:  929 , Purity : 0.731496062992126\n",
      "Avg purity :  0.8214421838410635\n"
     ]
    }
   ],
   "source": [
    "output_labels = kmeans_final(5,compressed_datamatrix)\n",
    "\n",
    "# for i in output_labels:\n",
    "purity = []\n",
    "for i in range(5):\n",
    "    max_label = max(set(output_labels[i]), key=output_labels[i].count)\n",
    "    dictio = Counter(output_labels[i])\n",
    "    purity.append(dictio[max_label]/len(output_labels[i]))\n",
    "    print(\"cluster : \",i,\", Maximum label present : \",max_label,\", No of times: \",dictio[max_label],\", Purity :\",purity[i])\n",
    "\n",
    "print(\"Avg purity : \", sum(purity)/len(purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 10859, 0: 6181, 4: 4791, 2: 2387, 1: 780})\n",
      "6181\n",
      "780\n",
      "2387\n",
      "10859\n",
      "4791\n",
      "cluster :  0 , Maximum label present :  dos , No of times:  6181 , Purity : 1.0\n",
      "cluster :  1 , Maximum label present :  normal , No of times:  612 , Purity : 0.7846153846153846\n",
      "cluster :  2 , Maximum label present :  dos , No of times:  1364 , Purity : 0.5714285714285714\n",
      "cluster :  3 , Maximum label present :  normal , No of times:  9838 , Purity : 0.9059766092642048\n",
      "cluster :  4 , Maximum label present :  normal , No of times:  2665 , Purity : 0.5562513045293258\n",
      "Avg purity :  0.7636543739674972\n"
     ]
    }
   ],
   "source": [
    "from sklearn import mixture\n",
    "clf = mixture.GaussianMixture(n_components=5)\n",
    "labels = clf.fit_predict(compressed_datamatrix)\n",
    "k = 5\n",
    "n = len(compressed_datamatrix)\n",
    "# In[94]:\n",
    "\n",
    "\n",
    "print(Counter(labels))\n",
    "\n",
    "\n",
    "# In[95]:\n",
    "\n",
    "\n",
    "output_labels3 = []\n",
    "\n",
    "for i in range(k):\n",
    "    output_labels3.append([])\n",
    "\n",
    "total_for_k_means = np.array(total_y_values)\n",
    "for i in range(n):\n",
    "    output_labels3[labels[i]].append(total_y_values[i])\n",
    "\n",
    "\n",
    "# In[96]:\n",
    "\n",
    "\n",
    "for i in output_labels3:\n",
    "    print(len(i))\n",
    "purity3 = []\n",
    "for i in range(k):\n",
    "    max_label = max(set(output_labels3[i]), key=output_labels3[i].count)\n",
    "    dictio = Counter(output_labels3[i])\n",
    "    purity3.append(dictio[max_label]/len(output_labels3[i]))\n",
    "    print(\"cluster : \",i,\", Maximum label present : \",max_label,\", No of times: \",dictio[max_label],\", Purity :\",purity3[i])\n",
    "\n",
    "print(\"Avg purity : \", sum(purity3)/len(purity3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## hiraerichal clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 24988, 2: 6, 0: 2, 3: 1, 4: 1})\n",
      "2\n",
      "24988\n",
      "6\n",
      "1\n",
      "1\n",
      "cluster :  0 , Maximum label present :  probe , No of times:  1 , Purity : 0.5\n",
      "cluster :  1 , Maximum label present :  normal , No of times:  13360 , Purity : 0.5346566351848887\n",
      "cluster :  2 , Maximum label present :  r2l , No of times:  4 , Purity : 0.6666666666666666\n",
      "cluster :  3 , Maximum label present :  normal , No of times:  1 , Purity : 1.0\n",
      "cluster :  4 , Maximum label present :  probe , No of times:  1 , Purity : 1.0\n",
      "Avg purity :  0.740264660370311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster_hir = AgglomerativeClustering(n_clusters=5,  linkage='single')  \n",
    "labels4 = cluster_hir.fit_predict(compressed_datamatrix)\n",
    "k = 5\n",
    "n = len(compressed_datamatrix)\n",
    "\n",
    "# In[98]:\n",
    "\n",
    "\n",
    "print(Counter(labels4))\n",
    "\n",
    "\n",
    "# In[99]:\n",
    "\n",
    "\n",
    "output_labels4 = []\n",
    "\n",
    "for i in range(k):\n",
    "    output_labels4.append([])\n",
    "\n",
    "total_for_k_means = np.array(total_y_values)\n",
    "for i in range(n):\n",
    "    output_labels4[labels4[i]].append(total_y_values[i])\n",
    "\n",
    "\n",
    "# In[100]:\n",
    "\n",
    "\n",
    "for i in output_labels4:\n",
    "    print(len(i))\n",
    "purity4 = []\n",
    "for i in range(k):\n",
    "    max_label = max(set(output_labels4[i]), key=output_labels4[i].count)\n",
    "    dictio = Counter(output_labels4[i])\n",
    "    purity4.append(dictio[max_label]/len(output_labels4[i]))\n",
    "    print(\"cluster : \",i,\", Maximum label present : \",max_label,\", No of times: \",dictio[max_label],\", Purity :\",purity4[i])\n",
    "\n",
    "print(\"Avg purity : \", sum(purity4)/len(purity4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pie Chart for all the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_purities = [sum(purity)/len(purity) , sum(purity3)/len(purity3) , sum(purity4)/len(purity4)]\n",
    "labels = [\"K-NN\",\"GMM\",\"Hierarchical\"]\n",
    "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "plt.figure(figsize=(10,12))\n",
    "explode = (0, 0, 0.1)\n",
    "plt.pie(avg_purities , explode = explode, labels=labels, colors=colors ,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140 )\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(14,input_dim=29,activation=\"sigmoid\"))\n",
    "model.add(Dense(29,input_dim=29,activation=\"sigmoid\"))\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24998/24998 [==============================] - 1s 26us/step - loss: 1.2187 - acc: 1.2001e-04\n",
      "Epoch 2/100\n",
      "24998/24998 [==============================] - 1s 22us/step - loss: 1.1528 - acc: 2.4002e-04\n",
      "Epoch 3/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 1.1029 - acc: 0.0013\n",
      "Epoch 4/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 1.0656 - acc: 0.0044\n",
      "Epoch 5/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 1.0373 - acc: 0.0351\n",
      "Epoch 6/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 1.0153 - acc: 0.0558\n",
      "Epoch 7/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9976 - acc: 0.0595\n",
      "Epoch 8/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9828 - acc: 0.0624\n",
      "Epoch 9/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9700 - acc: 0.0641\n",
      "Epoch 10/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9586 - acc: 0.0552\n",
      "Epoch 11/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9482 - acc: 0.0420\n",
      "Epoch 12/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9387 - acc: 0.0317\n",
      "Epoch 13/100\n",
      "24998/24998 [==============================] - 1s 21us/step - loss: 0.9299 - acc: 0.0293\n",
      "Epoch 14/100\n",
      "24998/24998 [==============================] - 1s 22us/step - loss: 0.9217 - acc: 0.0292\n",
      "Epoch 15/100\n",
      "24998/24998 [==============================] - 1s 36us/step - loss: 0.9140 - acc: 0.0292\n",
      "Epoch 16/100\n",
      "24998/24998 [==============================] - 1s 23us/step - loss: 0.9069 - acc: 0.0292\n",
      "Epoch 17/100\n",
      "24998/24998 [==============================] - 1s 22us/step - loss: 0.9002 - acc: 0.0296\n",
      "Epoch 18/100\n",
      "24998/24998 [==============================] - 1s 23us/step - loss: 0.8940 - acc: 0.0298\n",
      "Epoch 19/100\n",
      "24998/24998 [==============================] - 1s 22us/step - loss: 0.8882 - acc: 0.0300\n",
      "Epoch 20/100\n",
      "24998/24998 [==============================] - 1s 22us/step - loss: 0.8827 - acc: 0.0299\n",
      "Epoch 21/100\n",
      "24998/24998 [==============================] - 1s 24us/step - loss: 0.8776 - acc: 0.0300\n",
      "Epoch 22/100\n",
      "12960/24998 [==============>...............] - ETA: 0s - loss: 0.8625 - acc: 0.0292"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-96f495722fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_np_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_np_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(data_np_version,data_np_version,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(data_np_version[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.square(predictions[:,:] - data_np_version[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.sum(l,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.sum(b,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65011540672655633994"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c/(24998*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.mean(np.square(predictions - data_np_version),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6501154067265563399"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11453594, -0.42592784, -0.01001242, -0.0345061 , -0.09095369,\n",
       "        -0.02632138, -0.02193782, -0.02180098, -0.02791524, -0.04408631,\n",
       "        -0.60521684,  0.12721552, -0.63779946, -0.63165788, -0.37313313,\n",
       "        -0.37394367,  0.77000884, -0.34904443, -0.06425915, -1.6901791 ,\n",
       "         1.2628463 ,  1.06755048, -0.44107453, -0.25342043,  0.07102852,\n",
       "        -0.63948672, -0.53532098, -0.38606912, -0.37497461]],\n",
       "      dtype=float128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_np_version[:1,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
